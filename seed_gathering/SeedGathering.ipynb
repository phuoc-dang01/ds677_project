{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "805e9d4c-f390-4aba-9ec8-627b9ed85aea",
   "metadata": {},
   "source": [
    "### SEED GATHERING GET CONTENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfd3e144-73cb-42fa-9550-075c51686a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tree_sitter_parser import LANGUAGE, make_parser, node_to_string\n",
    "import datasets\n",
    "import os\n",
    "import signal\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "import boto3\n",
    "import smart_open\n",
    "from datasets import load_dataset,Dataset\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "s3 = boto3.client(\"s3\", config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "def download_contents(blob_id, src_encoding):\n",
    "    s3_url = f\"s3://softwareheritage/content/{blob_id}\"\n",
    "    with smart_open.open(s3_url, \"rb\", compression=\".gz\", transport_params={\"client\": s3}) as fin:\n",
    "        content = fin.read().decode(src_encoding)\n",
    "    \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eae6c31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "JAVA_METHOD_QUERY = LANGUAGE.query(\"\"\"\n",
    "(\n",
    "  (method_declaration\n",
    "    name: (identifier) @method.name\n",
    "    (modifiers)? @method.modifiers\n",
    "    (type_identifier)? @method.return_type\n",
    "    parameters: (formal_parameters) @method.parameters) @method.declaration\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "# JAVA_METHOD_QUERY = LANGUAGE.query(\"\"\"\n",
    "# (method_declaration\n",
    "#     name: (identifier) @method.name\n",
    "#     body: (block) @method.body\n",
    "# ) @method.declaration\n",
    "# \"\"\")\n",
    "\n",
    "\n",
    "def get_methods(src, tree):\n",
    "    captures = JAVA_METHOD_QUERY.captures(tree.root_node)\n",
    "    res = []\n",
    "    for capture in captures:\n",
    "        node, ty = capture\n",
    "        if ty != \"method.declaration\":\n",
    "            continue\n",
    "        # Filter for top-level methods (starting column 0)\n",
    "        _, col = node.start_point\n",
    "        if col != 0:\n",
    "            continue\n",
    "        res.append(node_to_string(src, node))\n",
    "    return res\n",
    "\n",
    "def parse_ex_java(parser, ex):\n",
    "    ex = download_contents(ex[\"blob_id\"], ex[\"src_encoding\"])\n",
    "    try:\n",
    "        buf = bytes(ex, \"utf8\")\n",
    "        tree = parser.parse(buf)\n",
    "        return get_methods(buf, tree)\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def process_chunk_java(idx_and_chunk):\n",
    "    assert PARSERS is not None\n",
    "    idx, chunk = idx_and_chunk\n",
    "    parser = PARSERS[idx]\n",
    "    chunk_new_methods = set()\n",
    "    for ex in chunk:\n",
    "        chunk_new_methods.update(parse_ex_java(parser, ex))\n",
    "    return chunk_new_methods\n",
    "\n",
    "def main_java(args):\n",
    "    global PARSERS\n",
    "    ds = datasets.load_dataset(\n",
    "        args.dataset,\n",
    "        data_dir=args.data_dir,\n",
    "        split=\"train\",\n",
    "    )\n",
    "    methods = set()\n",
    "    PARSERS = [make_parser() for _ in range(args.num_workers)]\n",
    "    total_len = len(ds)\n",
    "    CHUNK_SIZE = 1000 * args.num_workers\n",
    "\n",
    "    print(f\"Total length: {total_len}\")\n",
    "    print(f\"Chunk size: {CHUNK_SIZE}\")\n",
    "\n",
    "    chunk = []\n",
    "    p = Pool(args.num_workers)\n",
    "    for i, ex in enumerate(ds):\n",
    "        if i % (total_len // 100) == 0:\n",
    "            print(f\"{i}/{total_len}\")\n",
    "        try:\n",
    "            chunk.append(ex)\n",
    "            if len(chunk) == CHUNK_SIZE or i == total_len - 1:\n",
    "                print(f\"Processing chunk {i // CHUNK_SIZE}\")\n",
    "                subchunk_size = len(chunk) // args.num_workers\n",
    "                subchunks = [chunk[i:i + subchunk_size]\n",
    "                             for i in range(0, len(chunk), subchunk_size)]\n",
    "                new_methods_iter = p.imap(\n",
    "                    process_chunk_java, [(i, subchunk) for i, subchunk in enumerate(subchunks)])\n",
    "                print(\"Getting new methods\")\n",
    "                len_before = len(methods)\n",
    "                while True:\n",
    "                    try:\n",
    "                        def timeout_handler(_, __):\n",
    "                            raise KeyboardInterrupt\n",
    "                        signal.signal(signal.SIGALRM, timeout_handler)\n",
    "                        signal.alarm(60)\n",
    "                        methods.update(next(new_methods_iter))\n",
    "                        signal.alarm(0)\n",
    "                    except KeyboardInterrupt:\n",
    "                        signal.alarm(0)\n",
    "                        print(\"Keyboard interrupt. Terminating pool\")\n",
    "                        p.terminate()\n",
    "                        p = Pool(args.num_workers)\n",
    "                        break\n",
    "                    except StopIteration:\n",
    "                        break\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "\n",
    "                signal.alarm(0)\n",
    "\n",
    "                PARSERS = [make_parser() for _ in range(args.num_workers)]\n",
    "\n",
    "                print(\n",
    "                    f\"Done processing chunk {i // CHUNK_SIZE}. Got {len(methods) - len_before} new methods\")\n",
    "\n",
    "                chunk = []\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            chunk = []\n",
    "\n",
    "        if i == total_len - 1:\n",
    "            break\n",
    "\n",
    "    p.close()\n",
    "\n",
    "    new_ds_dict = {\n",
    "        \"content\": list(methods),\n",
    "        \"id\": list(range(len(methods)))\n",
    "    }\n",
    "\n",
    "    new_ds = datasets.Dataset.from_dict(new_ds_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37c058c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: method.declaration, Code: public void sayHello() {\n",
      "        System.out.println(\"Hello, world!\");\n",
      "    }\n",
      "Type: method.name, Code: sayHello\n",
      "Type: method.parameters, Code: ()\n",
      "Type: method.declaration, Code: public int add(int a, int b) {\n",
      "        return a + b;\n",
      "    }\n",
      "Type: method.name, Code: add\n",
      "Type: method.parameters, Code: (int a, int b)\n"
     ]
    }
   ],
   "source": [
    "code = \"\"\"\n",
    "public class Example {\n",
    "    public void sayHello() {\n",
    "        System.out.println(\"Hello, world!\");\n",
    "    }\n",
    "    public int add(int a, int b) {\n",
    "        return a + b;\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "parser = make_parser()  # Use your make_parser function\n",
    "tree = parser.parse(bytes(code, \"utf8\"))\n",
    "\n",
    "captures = JAVA_METHOD_QUERY.captures(tree.root_node)\n",
    "for node, ty in captures:\n",
    "    print(f\"Type: {ty}, Code: {node_to_string(bytes(code, 'utf8'), node)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74accea3-de2a-4b38-bbf2-b0c7f2be7aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMWORKERS = os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c8798ed1-24c7-4694-a97a-a381ab122392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf870ab19b314a30863be19b0c376b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/757 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['blob_id', 'directory_id', 'path', 'content_id', 'detected_licenses', 'license_type', 'repo_name', 'snapshot_id', 'revision_id', 'branch_name', 'visit_date', 'revision_date', 'committer_date', 'github_id', 'star_events_count', 'fork_events_count', 'gha_license_id', 'gha_event_created_at', 'gha_created_at', 'gha_language', 'src_encoding', 'language', 'is_vendor', 'is_generated', 'length_bytes', 'extension', 'filename'],\n",
      "    num_rows: 10001\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd34c7c0efe04ef69abb0d350478dffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/10001 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = datasets.load_dataset(\"bigcode/the-stack-v2-dedup\", \"Java\", cache_dir=\"../cache\", streaming=True, split=\"train\")\n",
    "\n",
    "data = []\n",
    "n =  10000\n",
    "for i, sample in enumerate(ds):\n",
    "    data.append(sample)\n",
    "    if i >= n:  # Stop after collecting 2000 samples\n",
    "        break\n",
    "\n",
    "map_style_dataset = Dataset.from_list(data)\n",
    "\n",
    "# Verify the Dataset\n",
    "print(map_style_dataset)\n",
    "\n",
    "map_style_dataset.save_to_disk(f\"sampled_dataset_{n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d601380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n =  10000\n",
    "loaded_dataset = Dataset.load_from_disk(f\"sampled_dataset_{n}\")\n",
    "ds = loaded_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "82541f12-dd45-44f7-ad0f-928224086086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length: 10001\n",
      "Chunk size: 20000\n"
     ]
    }
   ],
   "source": [
    "funs = set()\n",
    "PARSERS = [make_parser() for _ in range(NUMWORKERS)]\n",
    "total_len = len(ds)\n",
    "CHUNK_SIZE = 1000 * NUMWORKERS\n",
    "\n",
    "print(f\"Total length: {total_len}\")\n",
    "print(f\"Chunk size: {CHUNK_SIZE}\")\n",
    "\n",
    "chunk = []\n",
    "p = Pool(NUMWORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "78f242aa-2972-4037-b5d9-acc1f1cc7308",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 0\n",
      "Getting new functions\n",
      "list index out of range\n",
      "Done processing chunk 0. Got 267 new functions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['content', 'id'],\n",
       "    num_rows: 267\n",
       "})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, ex in enumerate(iter(ds)):\n",
    "    # if i % (total_len // 100) == 0:\n",
    "    #     print(f\"{i}/{total_len}\")\n",
    "    try:\n",
    "        chunk.append(ex)\n",
    "        if len(chunk) == CHUNK_SIZE or i == total_len - 1:\n",
    "            print(f\"Processing chunk {i // CHUNK_SIZE}\")\n",
    "            # divide the chunk into NUM_WORKERS chunks\n",
    "            subchunk_size = len(chunk) // NUMWORKERS\n",
    "            subchunks = [chunk[i:i + subchunk_size]\n",
    "                         for i in range(0, len(chunk), subchunk_size)]\n",
    "            new_funs_iter = p.imap(\n",
    "                process_chunk_java, [(i, subchunk) for i, subchunk in enumerate(subchunks)])\n",
    "            print(\"Getting new functions\")\n",
    "            len_before = len(funs)\n",
    "            while True:\n",
    "                try:\n",
    "                    def timeout_handler(_, __):\n",
    "                        raise KeyboardInterrupt  # it's fineeeeeee\n",
    "                    signal.signal(signal.SIGALRM, timeout_handler)\n",
    "                    signal.alarm(60)\n",
    "                    funs.update(next(new_funs_iter))\n",
    "                    signal.alarm(0)\n",
    "                except KeyboardInterrupt:\n",
    "                    signal.alarm(0)\n",
    "                    print(\"Keyboard interrupt. Terminating pool\")\n",
    "                    p.terminate()\n",
    "                    p = Pool(NUMWORKERS)\n",
    "                    break\n",
    "                except StopIteration:\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "\n",
    "            signal.alarm(0)\n",
    "\n",
    "            PARSERS = [make_parser() for _ in range(NUMWORKERS)]\n",
    "\n",
    "            print(\n",
    "                f\"Done processing chunk {i // CHUNK_SIZE}. Got {len(funs) - len_before} new functions\")\n",
    "\n",
    "            chunk = []\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        chunk = []\n",
    "\n",
    "    if i == total_len - 1:\n",
    "        break\n",
    "\n",
    "\n",
    "p.close()\n",
    "new_ds_dict = {\n",
    "    \"content\": list(funs),\n",
    "    \"id\": list(range(len(funs)))\n",
    "}\n",
    "\n",
    "new_ds = datasets.Dataset.from_dict(new_ds_dict)\n",
    "new_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d99d75d7-bac9-4f47-bb2c-a5773f46ea18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "public void setYear(int Yr)\n",
      "{\n",
      "if (Yr < 2000 || Yr > 2017)\n",
      "   Year =0;\n",
      "else\n",
      "   Year = Yr;\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "ds = new_ds\n",
    "print(ds['content'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afa60b0-bf47-4b30-93e2-2ee8a71958bf",
   "metadata": {},
   "source": [
    "### SEED GATHERING HIGH-QUALITY SUBSET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b8d3a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.load_from_disk(\"sampled_dataset_10000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "edd3300f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd169d4c4694463ba5581db92ad0e0df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=20):   0%|          | 0/10001 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = ds.map(\n",
    "    lambda row: {'content': download_contents(row['blob_id'], row['src_encoding'])},\n",
    "    num_proc=os.cpu_count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "89063770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import tempfile\n",
    "import signal\n",
    "import hashlib\n",
    "import os\n",
    "from typing import List, Dict\n",
    "from tqdm import tqdm\n",
    "from tree_sitter_parser import LANGUAGE, global_parser\n",
    "\n",
    "# Query to find return statements in Java code\n",
    "RETURN_QUERY = LANGUAGE.query(\"\"\"\n",
    "(return_statement) @return\n",
    "\"\"\")\n",
    "\n",
    "def does_have_return(src: str) -> bool:\n",
    "    \"\"\"\n",
    "    Check if the given Java code contains a return statement with a value.\n",
    "    \"\"\"\n",
    "    tree = global_parser.parse(bytes(src, \"utf8\"))\n",
    "    root = tree.root_node\n",
    "    captures = RETURN_QUERY.captures(root)\n",
    "    for node, _ in captures:\n",
    "        # If it doesn't have an argument, it's not a return with a value\n",
    "        if len(node.children) <= 1:  # Includes \"return\" itself\n",
    "            continue\n",
    "        else:\n",
    "            return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a5889ead-f07b-460e-8798-37df9b0c8257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering to only functions with return statements\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5249e5fdb4f4b0a824848f4a4509a0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=20):   0%|          | 0/10001 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['blob_id', 'directory_id', 'path', 'content_id', 'detected_licenses', 'license_type', 'repo_name', 'snapshot_id', 'revision_id', 'branch_name', 'visit_date', 'revision_date', 'committer_date', 'github_id', 'star_events_count', 'fork_events_count', 'gha_license_id', 'gha_event_created_at', 'gha_created_at', 'gha_language', 'src_encoding', 'language', 'is_vendor', 'is_generated', 'length_bytes', 'extension', 'filename', 'content'],\n",
       "    num_rows: 5835\n",
       "})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Filtering to only functions with return statements\")\n",
    "ds = ds.filter(lambda ex: does_have_return(\n",
    "    ex[\"content\"]), num_proc=os.cpu_count())\n",
    "ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fef71cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_javac(directory: str) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Runs the `javac` command in the given directory and parses the output to count errors for each file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"javac\", \"*.java\"],\n",
    "            cwd=directory,\n",
    "            capture_output=True,\n",
    "            timeout=120,\n",
    "            text=True,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error running javac: {e}\")\n",
    "        return {}\n",
    "\n",
    "    file_error_map = {}\n",
    "    error_lines = result.stderr.split(\"\\n\")\n",
    "    for line in error_lines:\n",
    "        if line.strip():\n",
    "            parts = line.split(\":\")\n",
    "            if len(parts) >= 2:\n",
    "                file_name = parts[0].strip()\n",
    "                if file_name not in file_error_map:\n",
    "                    file_error_map[file_name] = 0\n",
    "                if \"error\" in line:\n",
    "                    file_error_map[file_name] += 1\n",
    "\n",
    "    return file_error_map\n",
    "\n",
    "def typecheck_batch(files: List[str]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Type-checks a batch of Java files and filters out files with compilation errors.\n",
    "    \"\"\"\n",
    "    filemap: Dict[str, str] = {}\n",
    "    with tempfile.TemporaryDirectory() as tempdir:\n",
    "        for content in files:\n",
    "            # Generate a unique filename using SHA-1 hash\n",
    "            hash_object = hashlib.sha1(bytes(content, \"utf8\"))\n",
    "            hex_dig = hash_object.hexdigest()\n",
    "            filemap[hex_dig] = content\n",
    "            file_path = os.path.join(tempdir, hex_dig + \".java\")\n",
    "            with open(file_path, \"w\") as f:\n",
    "                f.write(content)\n",
    "\n",
    "        # Run javac in the temporary directory\n",
    "        error_map = run_javac(tempdir)\n",
    "        print(error_map)\n",
    "\n",
    "        if not error_map:\n",
    "            return {}\n",
    "\n",
    "        for file_name, error_count in error_map.items():\n",
    "            no_java = file_name.replace(\".java\", \"\")\n",
    "            if error_count > 0 and no_java in filemap:\n",
    "                del filemap[no_java]\n",
    "\n",
    "        print(f\"Pass rate: {len(filemap)}/{len(files)}\")\n",
    "        return filemap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8db3fd22-9743-45e8-b17a-2195a5119c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 250/5835 [00:00<00:09, 560.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 1, 'Usage': 0}\n",
      "Pass rate: 250/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 500/5835 [00:00<00:06, 776.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 1, 'Usage': 0}\n",
      "Pass rate: 250/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 750/5835 [00:00<00:05, 878.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 1, 'Usage': 0}\n",
      "Pass rate: 250/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1000/5835 [00:01<00:05, 938.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 1, 'Usage': 0}\n",
      "Pass rate: 250/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 1250/5835 [00:01<00:04, 928.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 1, 'Usage': 0}\n",
      "Pass rate: 250/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 1500/5835 [00:01<00:04, 981.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 1, 'Usage': 0}\n",
      "Pass rate: 250/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 1750/5835 [00:01<00:04, 1017.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 1, 'Usage': 0}\n",
      "Pass rate: 250/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 2000/5835 [00:02<00:03, 999.81it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 1, 'Usage': 0}\n",
      "Pass rate: 250/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 2250/5835 [00:02<00:03, 958.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 1, 'Usage': 0}\n",
      "Pass rate: 250/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 2500/5835 [00:02<00:03, 995.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 1, 'Usage': 0}\n",
      "Pass rate: 250/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 2750/5835 [00:02<00:03, 1016.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 1, 'Usage': 0}\n",
      "Pass rate: 250/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 3000/5835 [00:03<00:02, 1027.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 1, 'Usage': 0}\n",
      "Pass rate: 250/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 3250/5835 [00:03<00:02, 1038.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 1, 'Usage': 0}\n",
      "Pass rate: 250/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 3500/5835 [00:03<00:02, 1004.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 1, 'Usage': 0}\n",
      "Pass rate: 250/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 3750/5835 [00:03<00:02, 992.73it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 1, 'Usage': 0}\n",
      "Pass rate: 250/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 4000/5835 [00:04<00:01, 1001.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 1, 'Usage': 0}\n",
      "Pass rate: 250/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 4250/5835 [00:04<00:01, 1060.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 1, 'Usage': 0}\n",
      "Pass rate: 250/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 4739/5835 [00:04<00:00, 1121.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 1, 'Usage': 0}\n",
      "Pass rate: 250/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 4879/5835 [00:05<00:00, 974.28it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 1, 'Usage': 0}\n",
      "Pass rate: 250/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 5000/5835 [00:05<00:00, 852.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 1, 'Usage': 0}\n",
      "Pass rate: 250/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 5250/5835 [00:05<00:00, 937.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 1, 'Usage': 0}\n",
      "Pass rate: 250/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 5500/5835 [00:05<00:00, 1012.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 1, 'Usage': 0}\n",
      "Pass rate: 250/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5835/5835 [00:06<00:00, 963.18it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 1, 'Usage': 0}\n",
      "Pass rate: 250/250\n",
      "{'error': 1, 'Usage': 0}\n",
      "Pass rate: 85/85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch = []\n",
    "max_i = len(ds) - 1\n",
    "\n",
    "new_ds = {\n",
    "    \"content\": [],\n",
    "    \"sha1\": [],\n",
    "    \"id\": [],\n",
    "}\n",
    "\n",
    "e_id = 0\n",
    "for i, ex in enumerate(tqdm(ds, total=len(ds))):\n",
    "    try:\n",
    "        code = ex[\"content\"]\n",
    "\n",
    "        batch.append(code)\n",
    "\n",
    "        if len(batch) == 250 or i == max_i:\n",
    "            filemap = typecheck_batch(batch)\n",
    "            for sha1, contents in filemap.items():\n",
    "                new_ds[\"content\"].append(contents)\n",
    "                new_ds[\"sha1\"].append(sha1)\n",
    "                new_ds[\"id\"].append(e_id)\n",
    "                e_id += 1\n",
    "            batch = []\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"There was an error: {e}\")\n",
    "        continue\n",
    "\n",
    "new_ds_hf = datasets.Dataset.from_dict(new_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "83b53015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['content', 'sha1', 'id'],\n",
       "    num_rows: 5835\n",
       "})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ds_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "418df388-25a5-460d-825b-c95ede49b43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4fc596af7f94ad2b130571d2a61e7a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5835 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_dir = \"../datasets/Dec14\"\n",
    "new_ds_hf.save_to_disk(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b10a2057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c18203af23749bb811684780d85148b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "28491434"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ds_hf.to_json(\"../datasets/Dec14/sample_from_2000.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c67802-a173-4df2-b661-234745f0bfdf",
   "metadata": {},
   "source": [
    "### SEED GATHERING FILTER DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cb3c4493",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.load_from_disk(\"../datasets/Dec14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "01086352-e230-4267-9b7b-feab665f681a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import os\n",
    "from tree_sitter_parser import global_parser, LANGUAGE, make_parser\n",
    "import benchmark_data\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import argparse\n",
    "from vllm import LLM, SamplingParams\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e4ceb3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unindent(s):\n",
    "    \"\"\"\n",
    "    Remove leading indentation from a multi-line string.\n",
    "    \"\"\"\n",
    "    lines = s.splitlines()\n",
    "    non_blank_lines = [line for line in lines if line.strip()]\n",
    "    min_indent = min(len(line) - len(line.lstrip())\n",
    "                     for line in non_blank_lines) if non_blank_lines else 0\n",
    "    unindented_lines = [line[min_indent:] if len(\n",
    "        line) >= min_indent else line for line in lines]\n",
    "    return '\\n'.join(unindented_lines)\n",
    "\n",
    "\n",
    "def java_extract_javadoc(code):\n",
    "    \"\"\"\n",
    "    Extract the first Javadoc-style comment (`/* ... */`) from Java code\n",
    "    and return the comment along with the remaining code.\n",
    "\n",
    "    Args:\n",
    "        code (str): The Java code as a string.\n",
    "\n",
    "    Returns:\n",
    "        tuple: The extracted Javadoc comment (str) and the remaining code (str).\n",
    "    \"\"\"\n",
    "    # Find the opening of the Javadoc comment\n",
    "    first_comment_start = code.find(\"/*\")\n",
    "    if first_comment_start == -1:\n",
    "        raise ValueError(\"No Javadoc comment found in the code.\")\n",
    "\n",
    "    # Find the closing of the Javadoc comment\n",
    "    first_comment_end = code.find(\"*/\", first_comment_start)\n",
    "    if first_comment_end == -1:\n",
    "        raise ValueError(\"Javadoc comment is not properly closed.\")\n",
    "\n",
    "    # Extract the comment\n",
    "    comment = code[first_comment_start + 3:first_comment_end]  # Skip `/*` and include content\n",
    "    comment = unindent(comment).strip()  # Unindent and clean up the comment\n",
    "\n",
    "    # Remove the Javadoc comment from the code\n",
    "    remaining_code = code[:first_comment_start] + code[first_comment_end + 2:]\n",
    "\n",
    "    return comment, remaining_code.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4adfc94c-0964-4eaa-9e9c-7749bb4cf952",
   "metadata": {},
   "outputs": [],
   "source": [
    "FN_BLOCK_QUERY = LANGUAGE.query(\"\"\"\n",
    "(method_declaration\n",
    "    body: (block) @method-body)\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "def template_few_shot(code, answer, rationale):\n",
    "    doc, code = java_extract_javadoc(code)\n",
    "    assert answer == \"No\" or answer == \"Yes\"\n",
    "    prompt = f\"\"\"<issue_start>username_0: I have a function in Java and I'd like someone to check my description of this function.\n",
    "I'm doing this so that I can write a good docstring for this function.\n",
    "\n",
    "Here is the code for the function:\n",
    "```Java\n",
    "{code}\n",
    "```\n",
    "\n",
    "Here is my description of this program:\n",
    "```\n",
    "{doc}\n",
    "```\n",
    "\n",
    "Do not attempt to execute the function or to judge its correctness.\n",
    "Answer with \"Yes\" or \"No\" depending on if my description has enough information alone to re-implement the function.\n",
    "Also, answer with \"No\" if the description does not match the function.<issue_comment>username_1: Sure, no problem. I will be able to help.\n",
    "My answer is: {answer}\n",
    "\n",
    "{rationale}\n",
    "\n",
    "Upvotes: 200\"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "FEW_SHOTS = [\n",
    "    (\n",
    "        \"\"\"\n",
    "        public List<String> simpleScanNetwork() {\n",
    "            /*\n",
    "             * Do a simple network scan, which only works if your network configuration\n",
    "             * is 192.168.1.x\n",
    "             */\n",
    "            String baseIp = \"192.168.1.\";\n",
    "            List<String> addresses = new ArrayList<>();\n",
    "            addresses.add(\"127.0.0.1\");\n",
    "\n",
    "            for (int index = 1; index < 255; index++) {\n",
    "                addresses.add(baseIp + index);\n",
    "            }\n",
    "\n",
    "            return addresses;\n",
    "        }\n",
    "        \"\"\",\n",
    "        \"No\",\n",
    "        \"The simpleScanNetwork method you have provided seems to generate addresses that then would be used for a network scan, but does not actually perform it, unlike the method claims.\"\n",
    "    ),\n",
    "    (\n",
    "        \"\"\"\n",
    "        import java.util.*;\n",
    "        \n",
    "        public class DataFrameUtils {\n",
    "            public static DataFrame coerceInteger(DataFrame df) {\n",
    "                /*\n",
    "                 * Loop through the columns of a DataFrame. If it is numeric,\n",
    "                 * convert it to integer and fill missing values with zeros.\n",
    "                 * This is somewhat heavy-handed in an attempt to force\n",
    "                 * systems to recognize sparse columns as integers.\n",
    "                 */\n",
    "                List<String> except = Arrays.asList(\"latitude\", \"longitude\", \"zipCode\");\n",
    "\n",
    "                df.forEachColumn((name, series) -> {\n",
    "                    if (series.isNumeric() && !except.contains(name)) {\n",
    "                        series.fillNaN(0).toInteger();\n",
    "                    }\n",
    "                });\n",
    "\n",
    "                return df;\n",
    "            }\n",
    "        }\n",
    "        \"\"\",\n",
    "        \"Yes\",\n",
    "        \"The docstring does seem to match the implementation! The method loops through the columns of a DataFrame and coerces them as explained.\"\n",
    "    ),\n",
    "    (\n",
    "        \"\"\"\n",
    "        public class NameTransformer {\n",
    "            /*\n",
    "             * Converts a DataFrame to a dictionary.\n",
    "             *\n",
    "             * @param data The input DataFrame.\n",
    "             * @return A map containing transformed names.\n",
    "             */\n",
    "            public static Map<String, Map<String, String>> transformDataFrameToDict(DataFrame data) {\n",
    "                data.setColumn(\"en_name\", data.getColumn(\"en_name\").toUpperCase());\n",
    "                data.setColumn(\"en_name_f\", data.getColumn(\"en_name\").split(\" \")[0]);\n",
    "                data.setColumn(\"en_name_l\", data.getColumn(\"en_name\").split(\" \")[1]);\n",
    "                data.setColumn(\"jp_name_f\", data.getColumn(\"jp_name\").split(\"・\")[0]);\n",
    "                data.setColumn(\"jp_name_l\", data.getColumn(\"jp_name\").split(\"・\")[1]);\n",
    "\n",
    "                Map<String, String> fullNameMap = data.zipToMap(\"en_name\", \"jp_name\");\n",
    "                Map<String, String> firstNameMap = data.zipToMap(\"en_name_f\", \"jp_name_f\");\n",
    "                Map<String, String> lastNameMap = data.zipToMap(\"en_name_l\", \"jp_name_l\");\n",
    "\n",
    "                return Map.of(\n",
    "                    \"fullNameMap\", fullNameMap,\n",
    "                    \"firstNameMap\", firstNameMap,\n",
    "                    \"lastNameMap\", lastNameMap\n",
    "                );\n",
    "            }\n",
    "        }\n",
    "        \"\"\",\n",
    "        \"No\",\n",
    "        \"The transformDataFrameToDict method does indeed convert a DataFrame into a dictionary, but it transforms various columns that were not described in the docstring. For instance, nowhere in the docstring is it mentioned handling Japanese characters or the column names.\"\n",
    "    ),\n",
    "    (\n",
    "        \"\"\"\n",
    "        public double inchesToMeters(double inches) {\n",
    "            /*\n",
    "             * Convert inches to meters.\n",
    "             */\n",
    "            return inches * 0.0254;\n",
    "        }\n",
    "        \"\"\",\n",
    "        \"Yes\",\n",
    "        \"inchesToMeters is a very simple method. The docstring explains concisely its purpose, which is converting inches to meters.\"\n",
    "    ),\n",
    "    (\n",
    "        \"\"\"\n",
    "        public BufferedImage squareCrop(BufferedImage image, Integer targetSize) {\n",
    "            /*\n",
    "             * Crop the image to `targetSize`. If targetSize is null, the image\n",
    "             * is cropped to the smallest dimension, making it square.\n",
    "             */\n",
    "            int width = image.getWidth();\n",
    "            int height = image.getHeight();\n",
    "\n",
    "            if (targetSize == null) {\n",
    "                targetSize = Math.min(width, height);\n",
    "            }\n",
    "\n",
    "            int dx = (width - targetSize) / 2;\n",
    "            int dy = (height - targetSize) / 2;\n",
    "\n",
    "            return image.getSubimage(dx, dy, targetSize, targetSize);\n",
    "        }\n",
    "        \"\"\",\n",
    "        \"Yes\",\n",
    "        \"Following the standard description for docstrings for methods, the squareCrop method description tells exactly what the method does.\"\n",
    "    ),\n",
    "    (\n",
    "        \"\"\"\n",
    "        public Map<String, String> setupMotifFiles(Args args) {\n",
    "            /*\n",
    "             * Convenience method, ensures the setup is the same across\n",
    "             * multiplicity/orientation/spacing workflows.\n",
    "             */\n",
    "            Map<String, String> motifFiles = new HashMap<>();\n",
    "            motifFiles.put(\"early\", String.format(\"%s/%s/ggr.scanmotifs.h5\",\n",
    "                args.getInput(\"inference\").get(args.getCluster()).get(\"scanmotifs_dir\"),\n",
    "                args.getInput(\"inference\").get(args.getCluster()).get(\"scanmotifs_early_dir\")\n",
    "            ));\n",
    "            motifFiles.put(\"mid\", String.format(\"%s/%s/ggr.scanmotifs.h5\",\n",
    "                args.getInput(\"inference\").get(args.getCluster()).get(\"scanmotifs_dir\"),\n",
    "                args.getInput(\"inference\").get(args.getCluster()).get(\"scanmotifs_mid_dir\")\n",
    "            ));\n",
    "            motifFiles.put(\"late\", String.format(\"%s/%s/ggr.scanmotifs.h5\",\n",
    "                args.getInput(\"inference\").get(args.getCluster()).get(\"scanmotifs_dir\"),\n",
    "                args.getInput(\"inference\").get(args.getCluster()).get(\"scanmotifs_late_dir\")\n",
    "            ));\n",
    "            return motifFiles;\n",
    "        }\n",
    "        \"\"\",\n",
    "        \"No\",\n",
    "        \"The docstring for setupMotifFiles just says this is a convenience method. There is definitely not enough information to re-implement this method from the docstring alone.\"\n",
    "    ),\n",
    "    (\n",
    "        \"\"\"\n",
    "        public double trip(double[] u, double[] v) {\n",
    "            /*\n",
    "             * Returns the scalar triple product of vectors u and v and z-axis.\n",
    "             * The convention is z dot (u cross v). Dotting with the z-axis simplifies\n",
    "             * it to the z component of the u cross v.\n",
    "             *\n",
    "             * The product is:\n",
    "             * - positive if v is to the left of u, that is,\n",
    "             *   the shortest right-hand rotation from u to v is ccw.\n",
    "             * - negative if v is to the right of u, that is,\n",
    "             *   the shortest right-hand rotation from u to v is cw.\n",
    "             * - zero if v is collinear with u.\n",
    "             *\n",
    "             * Essentially, trip is the z component of the cross product of u x v.\n",
    "             */\n",
    "            return (u[0] * v[1] - u[1] * v[0]);\n",
    "        }\n",
    "        \"\"\",\n",
    "        \"Yes\",\n",
    "        \"The docstring for the trip method is very detailed and describes the method's purpose and the mathematical formula used to calculate the scalar triple product.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def prompt_fmt_java(code):\n",
    "    doc, code = java_extract_javadoc(code)\n",
    "    random.shuffle(FEW_SHOTS)\n",
    "    buf = \"\"\n",
    "    for few in FEW_SHOTS:\n",
    "        buf += template_few_shot(*few)\n",
    "    buf += f\"\"\"<issue_start>username_0: I have a function in Java and I'd like someone to check my description of this function.\n",
    "I'm doing this so that I can write a good docstring for this function.\n",
    "\n",
    "Here is the code for the function:\n",
    "```java\n",
    "{code}\n",
    "```\n",
    "\n",
    "Here is my description of this program:\n",
    "```\n",
    "{doc}\n",
    "```\n",
    "\n",
    "Do not attempt to execute the function or to judge its correctness.\n",
    "Answer with \"Yes\" or \"No\" depending on if my description has enough information alone to re-implement the function.\n",
    "Also, answer with \"No\" if the description does not match the function.\n",
    "Upvotes: 100<issue_comment>username_1: Sure, no problem. I will be able to help.\n",
    "My answer is:\"\"\"\n",
    "    return buf\n",
    "\n",
    "\n",
    "def auto_dtype():\n",
    "    if torch.cuda.is_bf16_supported():\n",
    "        return \"bfloat16\"\n",
    "    return \"auto\"\n",
    "\n",
    "\n",
    "def chunkify(lst, n):\n",
    "    chunks = []\n",
    "    for i in range(0, len(lst), n):\n",
    "        chunk = []\n",
    "        for j in range(n):\n",
    "            if i + j < len(lst):\n",
    "                chunk.append(lst[i + j])\n",
    "        chunks.append(chunk)\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cbcfa4b2-d3bb-4560-9578-8ce15d4d68de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['content', 'sha1', 'id'],\n",
       "    num_rows: 5835\n",
       "})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = ds\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d0992371-9ad5-4ad9-8aaa-d74b25eb4da0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5835 examples. Running pre-filtering...\n",
      "num strings from mbpp_docstrings: 120\n",
      "num strings from mbpp_solutions: 120\n",
      "num strings from human_eval_docstrings: 164\n",
      "num strings from human_eval_solutions: 161\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loaded {len(dataset)} examples. Running pre-filtering...\")\n",
    "\n",
    "BAD_WORDS = [\"todo\", \"fixme\", \"bug\"]\n",
    "BAD_IMPORTS = [\n",
    "    \"java.util.Scanner\", \n",
    "    \"java.lang.Runtime\", \n",
    "    \"java.lang.ProcessBuilder\", \n",
    "    \"javax.swing\", \n",
    "    \"java.awt\"\n",
    "]\n",
    "BAD_IMPORTS = [f\"import {b};\" for b in BAD_IMPORTS]\n",
    "# BAD_SUBSTRINGS = BAD_WORDS + BAD_IMPORTS\n",
    "BAD_SUBSTRINGS = BAD_WORDS\n",
    "\n",
    "bench_filter = benchmark_data.filter_out()\n",
    "all_bench = bench_filter[\"human_eval_docstrings\"] + \\\n",
    "    bench_filter[\"human_eval_solutions\"] + \\\n",
    "    bench_filter[\"mbpp_docstrings\"] + \\\n",
    "    bench_filter[\"mbpp_solutions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af077da-feac-4358-8702-e3c06927f0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/dill/_dill.py:414: PicklingWarning: Cannot locate reference to <class '_ctypes.PyCFuncPtrType'>.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n",
      "/usr/local/lib/python3.11/dist-packages/dill/_dill.py:414: PicklingWarning: Cannot pickle <class '_ctypes.PyCFuncPtrType'>: _ctypes.PyCFuncPtrType has recursive self-references that trigger a RecursionError.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf4934b3c3694e9db2c467dbd9f8d34a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=20):   0%|          | 0/5835 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['content', 'sha1', 'id'],\n",
       "    num_rows: 1289\n",
       "})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RETURN_QUERY = LANGUAGE.query(\"\"\"\n",
    "(return_statement) @return\n",
    "\"\"\")\n",
    "\n",
    "def does_have_return(src: str) -> bool:\n",
    "    \"\"\"\n",
    "    Check if the given Java code contains a return statement with a value.\n",
    "    \"\"\"\n",
    "    tree = global_parser.parse(bytes(src, \"utf8\"))\n",
    "    root = tree.root_node\n",
    "    captures = RETURN_QUERY.captures(root)\n",
    "    for node, _ in captures:\n",
    "        # If it doesn't have an argument, it's not a return with a value\n",
    "        if len(node.children) <= 1:  # Includes \"return\" itself\n",
    "            continue\n",
    "        else:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def pre_filtering_java(ex):\n",
    "    # \"\"\"\n",
    "    # Pre-filter Java code examples based on specific quality criteria.\n",
    "    # \"\"\"\n",
    "    code = ex[\"content\"]\n",
    "    code_bytes = code.encode('utf-8')\n",
    "\n",
    "    # # Filter out bad substrings\n",
    "    lower = code.lower()\n",
    "    for word in BAD_SUBSTRINGS:\n",
    "        if word in lower:\n",
    "            return False\n",
    "\n",
    "    # Too many lines of code -- say 150\n",
    "    lines = code.split(\"\\n\")\n",
    "    if len(lines) > 150:\n",
    "        return False\n",
    "\n",
    "    # # Exclude methods without meaningful parameters\n",
    "    for line in lines:\n",
    "        # Look for method declarations\n",
    "        if line.strip().startswith((\"public\", \"private\", \"protected\")) and \"()\" in line:\n",
    "            return False\n",
    "\n",
    "    # # Filter out methods with no return statement\n",
    "    parser = make_parser()\n",
    "    if not does_have_return(code):\n",
    "        return False\n",
    "\n",
    "    # try:\n",
    "    #     # Parse the Java code with Tree-sitter\n",
    "    #     tree = global_parser.parse(code_bytes)\n",
    "    #     block, _ = FN_BLOCK_QUERY.captures(tree.root_node)[0]\n",
    "\n",
    "    #     # Get the Javadoc, filter if not a valid Javadoc\n",
    "    #     preceding_comments = block.prev_sibling\n",
    "    #     if not preceding_comments or preceding_comments.type != \"comment\":\n",
    "    #         return False\n",
    "\n",
    "    #     # Extract and validate the Javadoc content\n",
    "    #     docstring_text = preceding_comments.text.decode('utf-8').strip()\n",
    "    #     # if not docstring_text.startswith(\"/*\") or not docstring_text.endswith(\"*/\"):\n",
    "    #     if not docstring_text.startswith(\"/*\") or not docstring_text.endswith(\"*/\"):\n",
    "    #         return False\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Error in filtering: {e}\")\n",
    "    #     return False\n",
    "\n",
    "    return True  # Passes all checks\n",
    "\n",
    "\n",
    "# threads = os.cpu_count() - 1  # type: ignore\n",
    "dataset = ds.filter(pre_filtering_java, num_proc=os.cpu_count())\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "39126a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce9975a0abf425ca28be0d22fac2746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1289 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.save_to_disk(\"../datasets/Dec14/Java_after_pre_filtering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7afc500",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241m.\u001b[39mload_from_disk(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../datasets/Dec14/Java_after_pre_filtering\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.load_from_disk(\"../datasets/Dec14/Java_after_pre_filtering\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9bb5f5-d5d8-468f-923e-8e8c94b99e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LLM(f\"../../../StarCoder\", dtype=auto_dtype(),\n",
    "            gpu_memory_utilization=0.95, tensor_parallel_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9ec3274",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "checkpoint = \"bigcode/starcoder2-15b\"\n",
    "# CHECKPOINT = \"bigcode/starcoderbase-1b\"\n",
    "# CHECKPOINT = \"bigcode/starcoder2-3b\"\n",
    "device = \"cuda\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01ae361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install bitsandbytes accelerate\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "# to use 4bit use `load_in_4bit=True` instead\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "\n",
    "checkpoint = \"bigcode/starcoder2-15b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "# model = AutoModelForCausalLM.from_pretrained(checkpoint, quantization_config=quantization_config).to(\"cuda\")\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint, quantization_config=quantization_config).to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e24e2a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['content', 'sha1', 'id'],\n",
       "    num_rows: 1289\n",
       "})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3188670a-403c-4e47-b230-22a3896fe9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running stage 3 filtering on 1289 examples...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Now running stage 3 filtering on {len(dataset)} examples...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d406ed80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package com.example.aichan2;\n",
      "\n",
      "import java.util.ArrayList;\n",
      "\n",
      "import android.app.Activity;\n",
      "import android.content.Intent;\n",
      "import android.speech.RecognizerIntent;\n",
      "import android.util.Log;\n",
      "\n",
      "public class Mike {\n",
      "\t/*\n",
      "\t *  音声認識用インテントの発行\n",
      "\t */\n",
      "\tpublic void start(Activity caller, int requestCode) {\n",
      "\t\tIntent intent = new Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH);\n",
      "\t\tintent.putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL, RecognizerIntent.LANGUAGE_MODEL_FREE_FORM);\n",
      "\t\tintent.putExtra(RecognizerIntent.EXTRA_PROMPT, \"なに？\");\n",
      "\t\t\n",
      "\t\tcaller.startActivityForResult(intent, requestCode);\n",
      "\t}\n",
      "\t\n",
      "\t/*\n",
      "\t *  onActivityResultが受け取ったdataから文字列のArrayListを取り出す\n",
      "\t */\n",
      "\tpublic ArrayList<String> getStringArrayList(Intent data) {\n",
      "\t\treturn data.getStringArrayListExtra(RecognizerIntent.EXTRA_RESULTS);\n",
      "\t}\n",
      "\t\n",
      "\t/*\n",
      "\t *  onActivityResultが受け取ったdataから一番最初の文字列を取り出す\n",
      "\t */\n",
      "\tpublic String getString(Intent data) {\n",
      "\t\tArrayList<String> result = data.getStringArrayListExtra(RecognizerIntent.EXTRA_RESULTS);\n",
      "\t\tfor(int i=0; i<result.size(); i++) {\n",
      "\t\t\tLog.i(\"Mike\", result.get(i));\n",
      "\t\t}\n",
      "\t\tif(result != null && result.size() != 0) {\n",
      "\t\t\treturn result.get(0);\n",
      "\t\t}\n",
      "\t\treturn null;\n",
      "\t}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[7]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "93838c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few-shot prompt has 2726 tokens\n"
     ]
    }
   ],
   "source": [
    "# Define a dummy Java function\n",
    "dummy_java = \"\"\"\n",
    "public class Dummy {\n",
    "    /*\n",
    "     * Dummy method for testing.\n",
    "     */\n",
    "    public void dummy() {\n",
    "        // This is a dummy function\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Apply formatting\n",
    "dummy_java_prompt = prompt_fmt_java(dummy_java)\n",
    "\n",
    "# Get tokens\n",
    "few_shot_toks = len(tokenizer.encode(dummy_java_prompt)) - len(tokenizer.encode(dummy_java))\n",
    "\n",
    "# Output the token overhead\n",
    "print(f\"Few-shot prompt has {few_shot_toks} tokens\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "624a4e6e-e67a-4207-9c74-9e2674946387",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtree_sitter_parser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LANGUAGE, global_parser\n\u001b[1;32m     11\u001b[0m prompts \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ex \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[43mdataset\u001b[49m, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataset), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m         code \u001b[38;5;241m=\u001b[39m ex[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import tempfile\n",
    "import signal\n",
    "import hashlib\n",
    "import os\n",
    "from typing import List, Dict\n",
    "from tqdm import tqdm\n",
    "from tree_sitter_parser import LANGUAGE, global_parser\n",
    "\n",
    "\n",
    "prompts = []\n",
    "for ex in tqdm(dataset, total=len(dataset), desc=\"Generating prompts\"):\n",
    "    try:\n",
    "        code = ex[\"content\"]\n",
    "        toks = len(tokenizer.encode(code)) + few_shot_toks\n",
    "        if toks > 16380:\n",
    "            print(f\"Skipping example with {toks} tokens\")\n",
    "            # to skip, just add dummy prompt\n",
    "            prompts.append(dummy_java_prompt)\n",
    "            continue\n",
    "        p = prompt_fmt_java(code)\n",
    "        prompts.append(p)\n",
    "    except:\n",
    "        continue\n",
    "# responses = []\n",
    "# for chunk in tqdm(chunkify(prompts, 512), desc=\"Generating responses\"):\n",
    "#     outs = model.generate(chunk, SamplingParams(\n",
    "#         temperature=0.0, stop=\"\\n\", max_tokens=5))\n",
    "#     contents = [o.outputs[0].text for o in outs]\n",
    "#     for c in contents:\n",
    "#         yes_count = c.lower().count(\"yes\")\n",
    "#         no_count = c.lower().count(\"no\")\n",
    "#         if yes_count > no_count:\n",
    "#             responses.append(True)\n",
    "#         elif yes_count < no_count:\n",
    "#             responses.append(False)\n",
    "#         else:\n",
    "#             # default to No\n",
    "#             responses.append(False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "eb8ccf04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<issue_start>username_0: I have a function in Java and I'd like someone to check my description of this function.\n",
      "I'm doing this so that I can write a good docstring for this function.\n",
      "\n",
      "Here is the code for the function:\n",
      "```Java\n",
      "public List<String> simpleScanNetwork() {\n",
      "            \n",
      "            String baseIp = \"192.168.1.\";\n",
      "            List<String> addresses = new ArrayList<>();\n",
      "            addresses.add(\"127.0.0.1\");\n",
      "\n",
      "            for (int index = 1; index < 255; index++) {\n",
      "                addresses.add(baseIp + index);\n",
      "            }\n",
      "\n",
      "            return addresses;\n",
      "        }\n",
      "```\n",
      "\n",
      "Here is my description of this program:\n",
      "```\n",
      "* Do a simple network scan, which only works if your network configuration\n",
      "* is 192.168.1.x\n",
      "```\n",
      "\n",
      "Do not attempt to execute the function or to judge its correctness.\n",
      "Answer with \"Yes\" or \"No\" depending on if my description has enough information alone to re-implement the function.\n",
      "Also, answer with \"No\" if the description does not match the function.<issue_comment>username_1: Sure, no problem. I will be able to help.\n",
      "My answer is: No\n",
      "\n",
      "The simpleScanNetwork method you have provided seems to generate addresses that then would be used for a network scan, but does not actually perform it, unlike the method claims.\n",
      "\n",
      "Upvotes: 200<issue_start>username_0: I have a function in Java and I'd like someone to check my description of this function.\n",
      "I'm doing this so that I can write a good docstring for this function.\n",
      "\n",
      "Here is the code for the function:\n",
      "```Java\n",
      "public Map<String, String> setupMotifFiles(Args args) {\n",
      "            \n",
      "            Map<String, String> motifFiles = new HashMap<>();\n",
      "            motifFiles.put(\"early\", String.format(\"%s/%s/ggr.scanmotifs.h5\",\n",
      "                args.getInput(\"inference\").get(args.getCluster()).get(\"scanmotifs_dir\"),\n",
      "                args.getInput(\"inference\").get(args.getCluster()).get(\"scanmotifs_early_dir\")\n",
      "            ));\n",
      "            motifFiles.put(\"mid\", String.format(\"%s/%s/ggr.scanmotifs.h5\",\n",
      "                args.getInput(\"inference\").get(args.getCluster()).get(\"scanmotifs_dir\"),\n",
      "                args.getInput(\"inference\").get(args.getCluster()).get(\"scanmotifs_mid_dir\")\n",
      "            ));\n",
      "            motifFiles.put(\"late\", String.format(\"%s/%s/ggr.scanmotifs.h5\",\n",
      "                args.getInput(\"inference\").get(args.getCluster()).get(\"scanmotifs_dir\"),\n",
      "                args.getInput(\"inference\").get(args.getCluster()).get(\"scanmotifs_late_dir\")\n",
      "            ));\n",
      "            return motifFiles;\n",
      "        }\n",
      "```\n",
      "\n",
      "Here is my description of this program:\n",
      "```\n",
      "* Convenience method, ensures the setup is the same across\n",
      "* multiplicity/orientation/spacing workflows.\n",
      "```\n",
      "\n",
      "Do not attempt to execute the function or to judge its correctness.\n",
      "Answer with \"Yes\" or \"No\" depending on if my description has enough information alone to re-implement the function.\n",
      "Also, answer with \"No\" if the description does not match the function.<issue_comment>username_1: Sure, no problem. I will be able to help.\n",
      "My answer is: No\n",
      "\n",
      "The docstring for setupMotifFiles just says this is a convenience method. There is definitely not enough information to re-implement this method from the docstring alone.\n",
      "\n",
      "Upvotes: 200<issue_start>username_0: I have a function in Java and I'd like someone to check my description of this function.\n",
      "I'm doing this so that I can write a good docstring for this function.\n",
      "\n",
      "Here is the code for the function:\n",
      "```Java\n",
      "public class NameTransformer {\n",
      "            \n",
      "            public static Map<String, Map<String, String>> transformDataFrameToDict(DataFrame data) {\n",
      "                data.setColumn(\"en_name\", data.getColumn(\"en_name\").toUpperCase());\n",
      "                data.setColumn(\"en_name_f\", data.getColumn(\"en_name\").split(\" \")[0]);\n",
      "                data.setColumn(\"en_name_l\", data.getColumn(\"en_name\").split(\" \")[1]);\n",
      "                data.setColumn(\"jp_name_f\", data.getColumn(\"jp_name\").split(\"・\")[0]);\n",
      "                data.setColumn(\"jp_name_l\", data.getColumn(\"jp_name\").split(\"・\")[1]);\n",
      "\n",
      "                Map<String, String> fullNameMap = data.zipToMap(\"en_name\", \"jp_name\");\n",
      "                Map<String, String> firstNameMap = data.zipToMap(\"en_name_f\", \"jp_name_f\");\n",
      "                Map<String, String> lastNameMap = data.zipToMap(\"en_name_l\", \"jp_name_l\");\n",
      "\n",
      "                return Map.of(\n",
      "                    \"fullNameMap\", fullNameMap,\n",
      "                    \"firstNameMap\", firstNameMap,\n",
      "                    \"lastNameMap\", lastNameMap\n",
      "                );\n",
      "            }\n",
      "        }\n",
      "```\n",
      "\n",
      "Here is my description of this program:\n",
      "```\n",
      "* Converts a DataFrame to a dictionary.\n",
      "*\n",
      "* @param data The input DataFrame.\n",
      "* @return A map containing transformed names.\n",
      "```\n",
      "\n",
      "Do not attempt to execute the function or to judge its correctness.\n",
      "Answer with \"Yes\" or \"No\" depending on if my description has enough information alone to re-implement the function.\n",
      "Also, answer with \"No\" if the description does not match the function.<issue_comment>username_1: Sure, no problem. I will be able to help.\n",
      "My answer is: No\n",
      "\n",
      "The transformDataFrameToDict method does indeed convert a DataFrame into a dictionary, but it transforms various columns that were not described in the docstring. For instance, nowhere in the docstring is it mentioned handling Japanese characters or the column names.\n",
      "\n",
      "Upvotes: 200<issue_start>username_0: I have a function in Java and I'd like someone to check my description of this function.\n",
      "I'm doing this so that I can write a good docstring for this function.\n",
      "\n",
      "Here is the code for the function:\n",
      "```Java\n",
      "public BufferedImage squareCrop(BufferedImage image, Integer targetSize) {\n",
      "            \n",
      "            int width = image.getWidth();\n",
      "            int height = image.getHeight();\n",
      "\n",
      "            if (targetSize == null) {\n",
      "                targetSize = Math.min(width, height);\n",
      "            }\n",
      "\n",
      "            int dx = (width - targetSize) / 2;\n",
      "            int dy = (height - targetSize) / 2;\n",
      "\n",
      "            return image.getSubimage(dx, dy, targetSize, targetSize);\n",
      "        }\n",
      "```\n",
      "\n",
      "Here is my description of this program:\n",
      "```\n",
      "* Crop the image to `targetSize`. If targetSize is null, the image\n",
      "* is cropped to the smallest dimension, making it square.\n",
      "```\n",
      "\n",
      "Do not attempt to execute the function or to judge its correctness.\n",
      "Answer with \"Yes\" or \"No\" depending on if my description has enough information alone to re-implement the function.\n",
      "Also, answer with \"No\" if the description does not match the function.<issue_comment>username_1: Sure, no problem. I will be able to help.\n",
      "My answer is: Yes\n",
      "\n",
      "Following the standard description for docstrings for methods, the squareCrop method description tells exactly what the method does.\n",
      "\n",
      "Upvotes: 200<issue_start>username_0: I have a function in Java and I'd like someone to check my description of this function.\n",
      "I'm doing this so that I can write a good docstring for this function.\n",
      "\n",
      "Here is the code for the function:\n",
      "```Java\n",
      "public double trip(double[] u, double[] v) {\n",
      "            \n",
      "            return (u[0] * v[1] - u[1] * v[0]);\n",
      "        }\n",
      "```\n",
      "\n",
      "Here is my description of this program:\n",
      "```\n",
      "* Returns the scalar triple product of vectors u and v and z-axis.\n",
      "* The convention is z dot (u cross v). Dotting with the z-axis simplifies\n",
      "* it to the z component of the u cross v.\n",
      "*\n",
      "* The product is:\n",
      "* - positive if v is to the left of u, that is,\n",
      "*   the shortest right-hand rotation from u to v is ccw.\n",
      "* - negative if v is to the right of u, that is,\n",
      "*   the shortest right-hand rotation from u to v is cw.\n",
      "* - zero if v is collinear with u.\n",
      "*\n",
      "* Essentially, trip is the z component of the cross product of u x v.\n",
      "```\n",
      "\n",
      "Do not attempt to execute the function or to judge its correctness.\n",
      "Answer with \"Yes\" or \"No\" depending on if my description has enough information alone to re-implement the function.\n",
      "Also, answer with \"No\" if the description does not match the function.<issue_comment>username_1: Sure, no problem. I will be able to help.\n",
      "My answer is: Yes\n",
      "\n",
      "The docstring for the trip method is very detailed and describes the method's purpose and the mathematical formula used to calculate the scalar triple product.\n",
      "\n",
      "Upvotes: 200<issue_start>username_0: I have a function in Java and I'd like someone to check my description of this function.\n",
      "I'm doing this so that I can write a good docstring for this function.\n",
      "\n",
      "Here is the code for the function:\n",
      "```Java\n",
      "public double inchesToMeters(double inches) {\n",
      "            \n",
      "            return inches * 0.0254;\n",
      "        }\n",
      "```\n",
      "\n",
      "Here is my description of this program:\n",
      "```\n",
      "* Convert inches to meters.\n",
      "```\n",
      "\n",
      "Do not attempt to execute the function or to judge its correctness.\n",
      "Answer with \"Yes\" or \"No\" depending on if my description has enough information alone to re-implement the function.\n",
      "Also, answer with \"No\" if the description does not match the function.<issue_comment>username_1: Sure, no problem. I will be able to help.\n",
      "My answer is: Yes\n",
      "\n",
      "inchesToMeters is a very simple method. The docstring explains concisely its purpose, which is converting inches to meters.\n",
      "\n",
      "Upvotes: 200<issue_start>username_0: I have a function in Java and I'd like someone to check my description of this function.\n",
      "I'm doing this so that I can write a good docstring for this function.\n",
      "\n",
      "Here is the code for the function:\n",
      "```Java\n",
      "import java.util.*;\n",
      "        \n",
      "        public class DataFrameUtils {\n",
      "            public static DataFrame coerceInteger(DataFrame df) {\n",
      "                \n",
      "                List<String> except = Arrays.asList(\"latitude\", \"longitude\", \"zipCode\");\n",
      "\n",
      "                df.forEachColumn((name, series) -> {\n",
      "                    if (series.isNumeric() && !except.contains(name)) {\n",
      "                        series.fillNaN(0).toInteger();\n",
      "                    }\n",
      "                });\n",
      "\n",
      "                return df;\n",
      "            }\n",
      "        }\n",
      "```\n",
      "\n",
      "Here is my description of this program:\n",
      "```\n",
      "* Loop through the columns of a DataFrame. If it is numeric,\n",
      "* convert it to integer and fill missing values with zeros.\n",
      "* This is somewhat heavy-handed in an attempt to force\n",
      "* systems to recognize sparse columns as integers.\n",
      "```\n",
      "\n",
      "Do not attempt to execute the function or to judge its correctness.\n",
      "Answer with \"Yes\" or \"No\" depending on if my description has enough information alone to re-implement the function.\n",
      "Also, answer with \"No\" if the description does not match the function.<issue_comment>username_1: Sure, no problem. I will be able to help.\n",
      "My answer is: Yes\n",
      "\n",
      "The docstring does seem to match the implementation! The method loops through the columns of a DataFrame and coerces them as explained.\n",
      "\n",
      "Upvotes: 200<issue_start>username_0: I have a function in Java and I'd like someone to check my description of this function.\n",
      "I'm doing this so that I can write a good docstring for this function.\n",
      "\n",
      "Here is the code for the function:\n",
      "```java\n",
      "package com.dnp.test.modular.controller;\n",
      "\n",
      "import com.dnp.test.modular.entity.UserRole;\n",
      "import com.dnp.test.modular.service.UserRoleService;\n",
      "import com.dnp.test.vo.PageVo;\n",
      "import io.swagger.annotations.Api;\n",
      "import io.swagger.annotations.ApiOperation;\n",
      "import io.swagger.annotations.ApiParam;\n",
      "import org.springframework.beans.factory.annotation.Autowired;\n",
      "import org.springframework.http.MediaType;\n",
      "import org.springframework.web.bind.annotation.*;\n",
      "\n",
      "\n",
      "@Api(value = \"UserRoleController\", description = \"用户角色\")\n",
      "@RestController\n",
      "@RequestMapping(value = \"/userRole\", produces = MediaType.APPLICATION_JSON_UTF8_VALUE)\n",
      "public class UserRoleController {\n",
      "    @Autowired\n",
      "    private UserRoleService userRoleService;\n",
      "\n",
      "    @RequestMapping(value = \"\", method = RequestMethod.GET)\n",
      "    @ApiOperation(value = \"查询所有用户角色\", notes = \"查询所有用户角色\")\n",
      "    public Object findAll(PageVo pageVo,\n",
      "                          @ApiParam(name = \"search\", value = \"模糊查询字段\", required = false) @RequestParam(required = false, defaultValue = \"\") String search) {\n",
      "        return null;\n",
      "    }\n",
      "\n",
      "\n",
      "    @RequestMapping(value = \"/{id}\", method = RequestMethod.GET)\n",
      "    @ApiOperation(value = \"查询用户角色详情\", notes = \"查询用户角色详情\", httpMethod = \"GET\")\n",
      "    public UserRole findById(@ApiParam(name = \"id\", value = \"用户角色id\", required = true) @PathVariable(\"id\") Integer id) {\n",
      "        return userRoleService.getById(id);\n",
      "    }\n",
      "\n",
      "    @RequestMapping(value = \"/{id}\", method = RequestMethod.PUT)\n",
      "    @ApiOperation(value = \"修改用户角色\", notes = \"修改用户角色\")\n",
      "    public void updateById(UserRole userRole) {\n",
      "        userRoleService.saveOrUpdate(userRole);\n",
      "    }\n",
      "\n",
      "    @RequestMapping(value = \"\", method = RequestMethod.POST)\n",
      "    @ApiOperation(value = \"添加用户角色\", notes = \"添加用户角色\")\n",
      "    public void save(\n",
      "\n",
      "            @ApiParam(name = \"userId\", value = \"用户id\")\n",
      "            @RequestParam(required = false, name = \"userId\") Long userId\n",
      "            ,\n",
      "            @ApiParam(name = \"roleId\", value = \"角色id\")\n",
      "            @RequestParam(required = false, name = \"roleId\") Long roleId\n",
      "    ) {\n",
      "        UserRole userRole = new UserRole(\n",
      "\n",
      "                userId, roleId);\n",
      "        userRoleService.save(userRole);\n",
      "    }\n",
      "\n",
      "    @RequestMapping(value = \"/{id}\", method = RequestMethod.DELETE)\n",
      "    @ApiOperation(value = \"删除用户角色\", notes = \"修改用户角色\")\n",
      "    public void deleteById(@ApiParam(name = \"id\", value = \"用户角色id\", required = true) @PathVariable(\"id\") Integer id) {\n",
      "        userRoleService.removeById(id);\n",
      "    }\n",
      "\n",
      "}\n",
      "```\n",
      "\n",
      "Here is my description of this program:\n",
      "```\n",
      "* <p>\n",
      "* 用户角色  前端控制器\n",
      "* </p>\n",
      "*\n",
      "* @author huazai\n",
      "* @since 2018-11-15\n",
      "```\n",
      "\n",
      "Do not attempt to execute the function or to judge its correctness.\n",
      "Answer with \"Yes\" or \"No\" depending on if my description has enough information alone to re-implement the function.\n",
      "Also, answer with \"No\" if the description does not match the function.\n",
      "Upvotes: 100<issue_comment>username_1: Sure, no problem. I will be able to help.\n",
      "My answer is:\n"
     ]
    }
   ],
   "source": [
    "print(prompts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a2d82e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]103.33it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]88.28it/s] \n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]120.56it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]103.49it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]89.31it/s] \n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]85.19it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]87.31it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s] 108.29it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s] 107.41it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s] 94.42it/s] \n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s] 103.25it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s] 114.97it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s] 128.83it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s] 133.68it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s] 136.71it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s] 150.86it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s] 135.17it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s] 130.51it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s] 123.28it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s] 150.71it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s] 142.08it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s] 142.23it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s] 128.50it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s] 106.86it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s] 106.76it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s] 106.47it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s] 109.76it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s] 110.42it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s] 112.42it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s] 108.04it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s] 106.65it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s] 99.48it/s] \n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s] 98.45it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s] 101.48it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s] 82.37it/s] \n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s] 90.81it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s] 94.87it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s] 97.60it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s] 110.67it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s] 94.70it/s] \n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s] 97.08it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s] 86.58it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s] 88.56it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s] 89.01it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s] 81.42it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s] 90.20it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s] 91.94it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s] 85.00it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s] 94.70it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s] 88.73it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s] 86.31it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s] 86.66it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s] 87.05it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s] 101.95it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/2 [00:00<?, ?it/s] 108.26it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s] 116.90it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s] 117.47it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s] 115.94it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s] 100.91it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s] 107.33it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s] 127.97it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s] 124.08it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s] 116.15it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s] 122.52it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s] 102.98it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s] 96.06it/s] \n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s] 96.63it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s] 89.03it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s] 87.69it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s] 90.93it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s] 91.39it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s] 102.58it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s] 104.39it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s] 119.43it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s] 108.39it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s] 115.96it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s], 97.87it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s], 105.34it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s], 100.90it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s], 93.07it/s] \n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s], 93.57it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s], 94.56it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s], 100.22it/s]\n",
      "Generating responses:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s], 84.50it/s] \n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s], 81.93it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s], 96.84it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s], 94.69it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s], 90.00it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s], 83.07it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s], 87.57it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s], 101.45it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s], 107.08it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s], 105.18it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s], 117.61it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s], 118.02it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s], 128.75it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s], 125.16it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s], 124.56it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s], 97.74it/s] \n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s], 85.70it/s]\n",
      "Generating responses:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Processing dataset: 100%|██████████| 1289/1289 [00:12<00:00, 103.55it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize responses and prompts\n",
    "responses = []\n",
    "prompts = []\n",
    "\n",
    "# Sampling parameters\n",
    "sampling_params = {\"temperature\": 0.0, \"stop\": \"\\n\", \"max_tokens\": 5}\n",
    "\n",
    "# Ensure sampling_params is a valid dictionary\n",
    "if sampling_params is None or not isinstance(sampling_params, dict):\n",
    "    sampling_params = {\"temperature\": 0.0, \"stop\": \"\\n\", \"max_tokens\": 5}\n",
    "\n",
    "# Generate prompts and responses\n",
    "for ex in tqdm(dataset, total=len(dataset), desc=\"Processing dataset\"):\n",
    "    try:\n",
    "        # Generate prompt\n",
    "        code = ex[\"content\"]\n",
    "        toks = len(tokenizer.encode(code)) + few_shot_toks\n",
    "        if toks > 16380:\n",
    "            print(f\"Skipping example with {toks} tokens\")\n",
    "            # Add dummy prompt for skipped examples\n",
    "            prompts.append(dummy_java_prompt)\n",
    "            continue\n",
    "\n",
    "        p = prompt_fmt_java(code)\n",
    "        prompts.append(p)\n",
    "\n",
    "        # Generate responses in chunks of 512 prompts\n",
    "        for chunk in tqdm(chunkify(prompts, 512), desc=\"Generating responses\"):\n",
    "            if chunk is None:\n",
    "                print(\"Warning: Encountered a None chunk. Skipping...\")\n",
    "                continue\n",
    "\n",
    "            # Generate responses for the chunk\n",
    "            outs = model.generate(chunk, sampling_params.copy())\n",
    "            contents = [o.outputs[0].text for o in outs]\n",
    "\n",
    "            for c in contents:\n",
    "                if c is None:\n",
    "                    print(\"Warning: Encountered None content. Treating as default response.\")\n",
    "                    responses.append(False)\n",
    "                    continue\n",
    "\n",
    "                # Count \"yes\" and \"no\" in the response\n",
    "                yes_count = c.lower().count(\"yes\")\n",
    "                no_count = c.lower().count(\"no\")\n",
    "\n",
    "                if yes_count > no_count:\n",
    "                    responses.append(True)\n",
    "                elif yes_count < no_count:\n",
    "                    responses.append(False)\n",
    "                else:\n",
    "                    # Default to No\n",
    "                    responses.append(False)\n",
    "    except Exception as e:\n",
    "        # Log any unexpected errors and skip to the next example\n",
    "        # print(f\"Error processing example: {e}\")\n",
    "        prompts.append(dummy_java_prompt)\n",
    "        responses.append(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a52604e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d576f56ce4504ebe8d3dd10a38ffe973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1289 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds.save_to_disk(\"../datasets/Dec17_Final_Step1_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5537bbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.load_from_disk(\"../datasets/Dec17_Final_Step1_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fc1a456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['seed', 'sha1', 'id'],\n",
       "    num_rows: 1289\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa02eef9-f557-4f36-adf3-0115a5c08041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import java.util.Arrays;\n",
      "\n",
      "public class BestTimeBuyAndSellStock {\n",
      "    //--------------  Solution 1 -------------------//\n",
      "    // brute force (Time Limit Exceeded)\n",
      "    public int maxProfit(int[] prices) {\n",
      "        int N = prices.length;\n",
      "        int res = 0;  // min, buy and sell on the same day\n",
      "        for (int i = 0; i < N; i++) {\n",
      "            for (int j = i; j < N; j++) {\n",
      "                res = Math.max(res, prices[j] - prices[i]);\n",
      "            }\n",
      "        }\n",
      "        return res;\n",
      "    }\n",
      "\n",
      "    //--------------  Solution 2  -------------------//\n",
      "    // most intuitive solution\n",
      "    public int maxProfit2(int[] prices) {\n",
      "        // input validation\n",
      "        if (prices == null || prices.length <= 1) {\n",
      "            return 0;\n",
      "        }\n",
      "\n",
      "        // record the min up util now\n",
      "        int min = Integer.MAX_VALUE;\n",
      "        int res = 0;\n",
      "        for (int i : prices) {\n",
      "            min = Math.min(min, i);\n",
      "            res = Math.max(res, i - min);\n",
      "        }\n",
      "        return res;\n",
      "    }\n",
      "\n",
      "    //--------------  Solution 3  -----------------//\n",
      "    // == maximal sub-array problem (diff)\n",
      "    public int maxProfit3(int[] prices) {\n",
      "        // input validation\n",
      "        if (prices == null || prices.length == 0) {\n",
      "            return 0;\n",
      "        }\n",
      "\n",
      "        // calculate the result\n",
      "        int sum = 0;\n",
      "        int res = 0;\n",
      "        for (int i = 0; i < prices.length; i++) {\n",
      "            int diff = prices[i + 1] - prices[i];  // get the diff\n",
      "            sum = Math.max(0, sum + diff);  // local\n",
      "            res = Math.max(res, sum);       // global\n",
      "        }\n",
      "        return res;\n",
      "    }\n",
      "\n",
      "\n",
      "    ////////////////////  TEST ////////////////////\n",
      "    private static void test(BestTimeBuyAndSellStock m, int[] A) {\n",
      "        System.out.println(Arrays.toString(A));\n",
      "        System.out.println(m.maxProfit(A) + \"\\n\");\n",
      "    }\n",
      "    public static void main(String[] args) {\n",
      "        BestTimeBuyAndSellStock solution = new BestTimeBuyAndSellStock();\n",
      "        int[] prices1 = {1, 2, 5, 3, 4, 6, 2, 8};\n",
      "        int[] prices2 = {7, 1, 5, 3, 6, 4};\n",
      "        test(solution, prices1);\n",
      "        test(solution, prices2);\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(ds['seed'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8d5579e1-7c33-438e-8e79-d8acab10b66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd857e0595df46ce80c5486e469f0bbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subset.save_to_disk(\"../datasets/Dec14_prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "da440e82-7104-4c01-99dc-b7dac8803cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c49a0062cb884e848070d3f13bed969f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 4156 examples\n"
     ]
    }
   ],
   "source": [
    "new_ds = subset.filter(  # horrible hack!\n",
    "    lambda ex, i: responses[i] and \"def dummy()\" not in ex[\"content\"], with_indices=True)\n",
    "print(f\"Filtered {len(dataset) - len(new_ds)} examples\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
